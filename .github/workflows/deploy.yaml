name: CI/CD Pipeline for Hello-World App

on:
  workflow_dispatch:

env:
  AWS_REGION: us-east-1
  CLUSTER_NAME: thrive-cluster-test
  ECR_REPOSITORY: hello-world
  IMAGE_TAG: ${{ github.sha }}

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: app/package-lock.json

      - name: Install dependencies
        working-directory: ./app
        run: npm ci

      - name: Run tests
        working-directory: ./app
        run: 'npm test || echo "No tests configured yet"'

      - name: Lint code
        working-directory: ./app
        run: 'npm run lint || echo "No linting configured yet"'

  build-and-push:
    needs: [test, deploy-infrastructure]
    runs-on: ubuntu-latest
    environment: AWS_ACCESS_KEY_ID
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Get ECR repository URI
        id: get-ecr
        run: |
          ECR_REPO=$(aws ecr describe-repositories --repository-names ${{ env.ECR_REPOSITORY }} --query 'repositories[0].repositoryUri' --output text)
          echo "ECR_REPO=$ECR_REPO" >> $GITHUB_OUTPUT
          echo "CLUSTER_NAME=${{ env.CLUSTER_NAME }}" >> $GITHUB_OUTPUT

      - name: Login to ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build, tag, and push image to ECR
        working-directory: ./app
        run: |
          docker build -t ${{ steps.get-ecr.outputs.ECR_REPO }}:${{ env.IMAGE_TAG }} .
          docker tag ${{ steps.get-ecr.outputs.ECR_REPO }}:${{ env.IMAGE_TAG }} ${{ steps.get-ecr.outputs.ECR_REPO }}:latest
          docker push ${{ steps.get-ecr.outputs.ECR_REPO }}:${{ env.IMAGE_TAG }}
          docker push ${{ steps.get-ecr.outputs.ECR_REPO }}:latest

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ steps.get-ecr.outputs.ECR_REPO }}:${{ env.IMAGE_TAG }}
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy scan results to GitHub Security tab
        uses: github/codeql-action/upload-sarif@v3
        if: always() && hashFiles('trivy-results.sarif') != ''
        with:
          sarif_file: 'trivy-results.sarif'

  deploy-infrastructure:
    needs: test
    runs-on: ubuntu-latest
    environment: AWS_ACCESS_KEY_ID
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Set GitHub repo environment variable
        run: echo "GITHUB_REPO=${{ github.repository }}" >> $GITHUB_ENV

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0

      - name: Terraform Format Check
        run: terraform fmt -check

      - name: Cache Terraform state
        uses: actions/cache@v3
        with:
          path: |
            .terraform
            terraform.tfstate
            terraform.tfstate.backup
          key: terraform-state-main
          restore-keys: |
            terraform-state-

      - name: Terraform Init
        run: terraform init

      - name: Cache Terraform state after init
        if: always()
        uses: actions/cache/save@v3
        with:
          path: |
            .terraform
            terraform.tfstate
            terraform.tfstate.backup
          key: terraform-state-main

      - name: Terraform Validate
        run: terraform validate

      - name: Check for existing resources
        run: |
          echo "üîç Checking for existing AWS resources..."
          
          # Check if ECR repository exists
          if aws ecr describe-repositories --repository-names ${{ env.ECR_REPOSITORY }} --region ${{ env.AWS_REGION }} 2>/dev/null; then
            echo "‚ö†Ô∏è ECR repository '${{ env.ECR_REPOSITORY }}' already exists"
            echo "EXISTING_ECR=true" >> $GITHUB_ENV
          else
            echo "‚úÖ ECR repository '${{ env.ECR_REPOSITORY }}' does not exist"
            echo "EXISTING_ECR=false" >> $GITHUB_ENV
          fi
          
          # Check if EKS cluster exists
          if aws eks describe-cluster --name ${{ env.CLUSTER_NAME }} --region ${{ env.AWS_REGION }} 2>/dev/null; then
            echo "‚ö†Ô∏è EKS cluster '${{ env.CLUSTER_NAME }}' already exists"
            echo "EXISTING_EKS=true" >> $GITHUB_ENV
          else
            echo "‚úÖ EKS cluster '${{ env.CLUSTER_NAME }}' does not exist"
            echo "EXISTING_EKS=false" >> $GITHUB_ENV
          fi
          
          # Check if IAM roles exist
          for role in "thrive-cluster-test-cluster-role" "thrive-cluster-test-node-role" "thrive-cluster-test-github-actions-role" "hello-world-pod-role"; do
            if aws iam get-role --role-name $role --region ${{ env.AWS_REGION }} 2>/dev/null; then
              echo "‚ö†Ô∏è IAM role '$role' already exists"
            else
              echo "‚úÖ IAM role '$role' does not exist"
            fi
          done

      - name: Terraform Plan
        run: |
          terraform plan \
            -var="github_repo=$GITHUB_REPO" \
            -var="aws_access_key_id=${{ secrets.AWS_ACCESS_KEY_ID }}" \
            -var="aws_secret_access_key=${{ secrets.AWS_SECRET_ACCESS_KEY }}" \
            -out=tfplan

      - name: Cache Terraform state after plan
        if: always()
        uses: actions/cache/save@v3
        with:
          path: |
            .terraform
            terraform.tfstate
            terraform.tfstate.backup
          key: terraform-state-main

      - name: Terraform Apply
        id: terraform-apply
        run: |
          terraform apply \
            -var="github_repo=$GITHUB_REPO" \
            -var="aws_access_key_id=${{ secrets.AWS_ACCESS_KEY_ID }}" \
            -var="aws_secret_access_key=${{ secrets.AWS_SECRET_ACCESS_KEY }}" \
            -auto-approve

      - name: Cache Terraform state after apply
        if: always()
        uses: actions/cache/save@v3
        with:
          path: |
            .terraform
            terraform.tfstate
            terraform.tfstate.backup
          key: terraform-state-main

  cleanup-on-failure:
    needs: [deploy-infrastructure]
    runs-on: ubuntu-latest
    environment: AWS_ACCESS_KEY_ID
    if: failure() && needs.deploy-infrastructure.result == 'failure'
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Set GitHub repo environment variable
        run: echo "GITHUB_REPO=${{ github.repository }}" >> $GITHUB_ENV

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0

      - name: Cache Terraform state
        uses: actions/cache@v3
        with:
          path: |
            .terraform
            terraform.tfstate
            terraform.tfstate.backup
          key: terraform-state-main
          restore-keys: |
            terraform-state-
          fail-on-cache-miss: false

      - name: Terraform Init
        run: terraform init

      - name: Terraform Destroy
        run: |
          echo "üßπ Running terraform destroy to clean up any partially created resources..."
          
          # Check if we have any resources in state
          if terraform state list 2>/dev/null | grep -q .; then
            echo "üìã Found resources in Terraform state, destroying them..."
            terraform destroy \
              -var="github_repo=$GITHUB_REPO" \
              -var="aws_access_key_id=${{ secrets.AWS_ACCESS_KEY_ID }}" \
              -var="aws_secret_access_key=${{ secrets.AWS_SECRET_ACCESS_KEY }}" \
              -auto-approve
            echo "‚úÖ Terraform destroy completed"
          else
            echo "‚ÑπÔ∏è No resources found in Terraform state - this means the deployment failed before any resources were created"
            echo "‚ÑπÔ∏è Proceeding with manual cleanup of any resources that might exist..."
          fi

      - name: Clean up any remaining resources not in state
        run: |
          echo "üßπ Cleaning up any remaining AWS resources that may not be in Terraform state..."
          
          # Clean up ECR repository and images (if not in state)
          if aws ecr describe-repositories --repository-names ${{ env.ECR_REPOSITORY }} --region ${{ env.AWS_REGION }} 2>/dev/null; then
            echo "üóëÔ∏è Deleting ECR repository and images..."
            # Delete all images first
            IMAGES=$(aws ecr list-images --repository-name ${{ env.ECR_REPOSITORY }} --region ${{ env.AWS_REGION }} --query 'imageIds[*]' --output json 2>/dev/null || echo '[]')
            if [ "$IMAGES" != "[]" ] && [ "$IMAGES" != "null" ]; then
              aws ecr batch-delete-image --repository-name ${{ env.ECR_REPOSITORY }} --region ${{ env.AWS_REGION }} --image-ids "$IMAGES" || echo "‚ö†Ô∏è Some images may have already been deleted"
            fi
            # Delete repository
            aws ecr delete-repository --repository-name ${{ env.ECR_REPOSITORY }} --region ${{ env.AWS_REGION }} --force || echo "‚ö†Ô∏è Repository may have already been deleted"
          fi
          
          # Clean up EKS cluster (if not in state)
          if aws eks describe-cluster --name ${{ env.CLUSTER_NAME }} --region ${{ env.AWS_REGION }} 2>/dev/null; then
            echo "üóëÔ∏è Deleting EKS cluster..."
            # Delete node groups first
            NODE_GROUPS=$(aws eks list-nodegroups --cluster-name ${{ env.CLUSTER_NAME }} --region ${{ env.AWS_REGION }} --query 'nodegroups' --output text 2>/dev/null || echo "")
            if [ -n "$NODE_GROUPS" ] && [ "$NODE_GROUPS" != "None" ]; then
              for nodegroup in $NODE_GROUPS; do
                echo "üóëÔ∏è Deleting node group: $nodegroup"
                aws eks delete-nodegroup --cluster-name ${{ env.CLUSTER_NAME }} --nodegroup-name $nodegroup --region ${{ env.AWS_REGION }} || echo "‚ö†Ô∏è Node group may have already been deleted"
              done
            fi
            # Wait for node groups to be deleted
            echo "‚è≥ Waiting for node groups to be deleted..."
            sleep 60
            # Delete cluster
            aws eks delete-cluster --name ${{ env.CLUSTER_NAME }} --region ${{ env.AWS_REGION }} || echo "‚ö†Ô∏è Cluster may have already been deleted"
          fi
          
          # Clean up IAM roles (if not in state)
          for role in "thrive-cluster-test-cluster-role" "thrive-cluster-test-node-role" "thrive-cluster-test-github-actions-role" "hello-world-pod-role"; do
            if aws iam get-role --role-name $role --region ${{ env.AWS_REGION }} 2>/dev/null; then
              echo "üóëÔ∏è Deleting IAM role: $role"
              # Detach policies first
              aws iam list-attached-role-policies --role-name $role --query 'AttachedPolicies[*].PolicyArn' --output text | xargs -I {} aws iam detach-role-policy --role-name $role --policy-arn {} 2>/dev/null || echo "‚ö†Ô∏è No policies to detach"
              # Delete role
              aws iam delete-role --role-name $role --region ${{ env.AWS_REGION }} || echo "‚ö†Ô∏è Role may have already been deleted"
            fi
          done
          
          # Clean up Secrets Manager secrets (if not in state)
          for secret in "thrive-cluster-test-github-actions-credentials" "thrive-cluster-test-app-secrets"; do
            if aws secretsmanager describe-secret --secret-id $secret --region ${{ env.AWS_REGION }} 2>/dev/null; then
              echo "üóëÔ∏è Deleting secret: $secret"
              aws secretsmanager delete-secret --secret-id $secret --region ${{ env.AWS_REGION }} --force-delete-without-recovery || echo "‚ö†Ô∏è Secret may have already been deleted"
            fi
          done
          
          # Clean up CloudWatch log groups (if not in state)
          if aws logs describe-log-groups --log-group-name-prefix "/aws/eks/${{ env.CLUSTER_NAME }}" --region ${{ env.AWS_REGION }} --query 'logGroups[0].logGroupName' --output text 2>/dev/null | grep -q "${{ env.CLUSTER_NAME }}"; then
            echo "üóëÔ∏è Deleting CloudWatch log groups..."
            aws logs delete-log-group --log-group-name "/aws/eks/${{ env.CLUSTER_NAME }}/cluster" --region ${{ env.AWS_REGION }} || echo "‚ö†Ô∏è Log group may have already been deleted"
          fi
          
          # Clean up OIDC providers (if not in state)
          OIDC_PROVIDERS=$(aws iam list-open-id-connect-providers --region ${{ env.AWS_REGION }} --query 'OpenIDConnectProviderList[?contains(Arn, `thrive-cluster-test`)].Arn' --output text 2>/dev/null || echo "")
          if [ -n "$OIDC_PROVIDERS" ]; then
            for provider in $OIDC_PROVIDERS; do
              echo "üóëÔ∏è Deleting OIDC provider: $provider"
              aws iam delete-open-id-connect-provider --open-id-connect-provider-arn "$provider" --region ${{ env.AWS_REGION }} || echo "‚ö†Ô∏è OIDC provider may have already been deleted"
            done
          fi
          
          echo "‚úÖ Cleanup completed. You can now retry the deployment."

      - name: Cache Terraform state after cleanup
        if: always()
        uses: actions/cache/save@v3
        with:
          path: |
            .terraform
            terraform.tfstate
            terraform.tfstate.backup
          key: terraform-state-main

  deploy-application:
    needs: [build-and-push, deploy-infrastructure, cleanup-on-failure]
    if: always() && needs.deploy-infrastructure.result == 'success'
    runs-on: ubuntu-latest
    environment: AWS_ACCESS_KEY_ID
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Get ECR repository URI
        id: get-ecr
        run: |
          ECR_REPO=$(aws ecr describe-repositories --repository-names ${{ env.ECR_REPOSITORY }} --query 'repositories[0].repositoryUri' --output text)
          echo "ECR_REPO=$ECR_REPO" >> $GITHUB_OUTPUT
          echo "CLUSTER_NAME=${{ env.CLUSTER_NAME }}" >> $GITHUB_OUTPUT

      - name: Update kubeconfig
        run: aws eks update-kubeconfig --name ${{ steps.get-ecr.outputs.CLUSTER_NAME }} --region ${{ env.AWS_REGION }}

      - name: Deploy to EKS
        run: |
          # Update image tag in deployment
          sed -i "s|ACCOUNT_ID.dkr.ecr.REGION.amazonaws.com/hello-world:latest|${{ steps.get-ecr.outputs.ECR_REPO }}:${{ env.IMAGE_TAG }}|g" k8s/deployment.yaml
          
          # Apply all Kubernetes manifests
          kubectl apply -f k8s/

      - name: Wait for deployment
        run: |
          kubectl rollout status deployment/hello-world --timeout=300s

      - name: Verify deployment
        run: |
          kubectl get pods -l app=hello-world
          kubectl get services
          kubectl get ingress

  notify:
    needs: [deploy-application]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Notify deployment status
        run: |
          if [ "${{ needs.deploy-application.result }}" == "success" ]; then
            echo "‚úÖ Deployment successful!"
          else
            echo "‚ùå Deployment failed!"
          fi
